{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, \"r\") as data:\n",
    "        lines = data.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "def fixed_length_chunks(string, length):\n",
    "    chunks = list( (string[0+i:length+i] for i in range(0, len(string), length)) )\n",
    "    last_chunk_length_diff = length - len(chunks[-1])\n",
    "    # force last chunk to be fixed length by adding a part from the penultimate chunk\n",
    "    if len(chunks) > 1 and last_chunk_length_diff != 0:\n",
    "        chunks[-1] = (chunks[-2] + chunks[-1])[-length:]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for training data\n",
    "\n",
    "def remove_duplicates(chunks):\n",
    "    \"\"\"Removes duplicate chunks (use only for training data).\"\"\"\n",
    "    duplicates = set()\n",
    "    output = []\n",
    "    for chunk in chunks:\n",
    "        if chunk not in duplicates:\n",
    "            duplicates.add(chunk)\n",
    "            output.append(chunk)\n",
    "    return output\n",
    "\n",
    "def process_train_sequences(sequences, chunk_length):\n",
    "    chunked_sequences = [fixed_length_chunks(seq, chunk_length) for seq in sequences]\n",
    "    chunks = [chunk for chunks in chunked_sequences for chunk in chunks]\n",
    "    return remove_duplicates(chunks)    \n",
    "\n",
    "def write_train_data(chunks, out_dir):\n",
    "    with open(out_dir, \"w\") as train:\n",
    "        train.write('\\n'.join(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for test data\n",
    "\n",
    "def read_test_and_labels(path_no_ext):\n",
    "    test = read_data(path_no_ext + \".test\")\n",
    "    labels = read_data(path_no_ext + \".labels\")\n",
    "    return test, labels\n",
    "\n",
    "def process_test_sequences(labeled_sequences, chunk_length):\n",
    "    chunked_sequences = [list( map(lambda x: (x, label), \n",
    "                                   fixed_length_chunks(seq, chunk_length)) \n",
    "                             )\n",
    "                         for seq, label in labeled_sequences]\n",
    "    chunks = [chunk for chunks in chunked_sequences for chunk in chunks]\n",
    "    return chunks\n",
    "\n",
    "def write_test_data(labeled_chunks, out_dir_no_ext):\n",
    "    chunks = [chunk for chunk, _ in labeled_chunks]\n",
    "    lbls = [label for _, label in labeled_chunks]\n",
    "    with open(out_dir_no_ext + \".test\", \"w\") as test, open(out_dir_no_ext + \".labels\", \"w\") as labels:\n",
    "        test.write('\\n'.join(chunks))\n",
    "        labels.write('\\n'.join(lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CERT = \"negative-selection/syscalls/snd-cert/\"\n",
    "UNM = \"negative-selection/syscalls/snd-unm/\"\n",
    "OUT = \"syscalls-classification/\"\n",
    "CHUNK_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_data(chunk_length):\n",
    "    # snd-cert\n",
    "    train_cert = read_data(CERT + \"snd-cert.train\")\n",
    "    chunks_cert = process_train_sequences(train_cert, chunk_length)\n",
    "    write_train_data(chunks_cert, OUT + \"snd-cert/snd-cert.train\")\n",
    "    # snd-unm\n",
    "    train_unm = read_data(UNM+ \"snd-unm.train\")\n",
    "    chunks_unm = process_train_sequences(train_unm, chunk_length)\n",
    "    write_train_data(chunks_unm, OUT + \"snd-unm/snd-unm.train\")\n",
    "    \n",
    "def preprocess_test_data(chunk_length):\n",
    "    for i in range(1, 4):\n",
    "        # snd-cert\n",
    "        test_cert, labels_cert = read_test_and_labels(CERT + f\"snd-cert.{i}\")\n",
    "        labeled_chunks_cert = process_test_sequences(zip(test_cert, labels_cert), chunk_length)\n",
    "        write_test_data(labeled_chunks_cert, OUT + f\"snd-cert/snd-cert.{i}\")\n",
    "        # snd-unm\n",
    "        test_unm, labels_unm = read_test_and_labels(UNM + f\"snd-unm.{i}\")\n",
    "        labeled_chunks_unm = process_test_sequences(zip(test_unm, labels_unm), chunk_length)\n",
    "        write_test_data(labeled_chunks_unm, OUT + f\"snd-unm/snd-unm.{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_train_data(CHUNK_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_test_data(CHUNK_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic example\n",
    "cert_data_path = OUT + \"snd-cert/\"\n",
    "jar = f\"-jar negative-selection/negsel2.jar\"\n",
    "alpha = f\"-alphabet file://{CERT}snd-cert.alpha\"\n",
    "self = f\"-self {cert_data_path}snd-cert.train\"\n",
    "params = \"-n 10 -r 4 -c -l\"\n",
    "test = f\"{cert_data_path}snd-cert.1.test\"\n",
    "\n",
    "output = !java {jar} {alpha} {self} {params} < {test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0716324717054313"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some values are 'nan'\n",
    "counts = [float(x) for x in output]\n",
    "np.nanmean(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
