{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from data import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './tadpole_challenge/'\n",
    "X, y, label_dict = get_data(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split with class balance in mind\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = sum(y_pred == y) / len(y)\n",
    "    return acc\n",
    "\n",
    "def metrics(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_prob = clf.predict_proba(X)\n",
    "    BCA = balanced_accuracy_score(y, y_pred)\n",
    "    mAUC = roc_auc_score(y, y_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "    return BCA, mAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_accuracy(clf):\n",
    "    train_acc = accuracy(clf, X_train, y_train)\n",
    "    test_acc = accuracy(clf, X_test, y_test)\n",
    "    print('Train accuracy:', train_acc)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    \n",
    "def report_metrics(clf, verbose):\n",
    "    BCA_train, mAUC_train = metrics(clf, X_train, y_train)\n",
    "    BCA_test, mAUC_test = metrics(clf, X_test, y_test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\tTrain metrics')    \n",
    "        print('BCA_train:', BCA_train)\n",
    "        print('mAUC_train:', mAUC_train)\n",
    "\n",
    "        print('\\tTest metrics')   \n",
    "        print('BCA_test:', BCA_test)\n",
    "        print('mAUC_test:', mAUC_test)\n",
    "    \n",
    "    return BCA_train, BCA_test, mAUC_train, mAUC_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings are not final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_clf(clf):\n",
    "    return BaggingClassifier(base_estimator = clf, \n",
    "                             n_estimators = 100, \n",
    "                             max_samples = 0.3, \n",
    "                             random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Classifier, verbose=False, **kwargs):\n",
    "    if verbose: print('+ Base learner')\n",
    "    clf = Classifier(**kwargs).fit(X_train, y_train)\n",
    "    clf_perf = report_metrics(clf, verbose)\n",
    "    \n",
    "    if verbose: print('\\n+ Ensemble')\n",
    "    bag_clf = bagging_clf(Classifier(**kwargs)).fit(X_train, y_train)\n",
    "    bag_clf_perf = report_metrics(bag_clf, verbose)\n",
    "    \n",
    "    # Values in dict are lists of the following format: \n",
    "    # BCA_train, BCA_test, mAUC_train, mAUC_test\n",
    "    if not verbose:\n",
    "        return {'clf': list(clf_perf), 'bag_clf': list(bag_clf_perf)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a main for every baselearner that runs them multiple times\n",
    "# because SVC requires extra arguments, which makes it difficult\n",
    "# to generalize into one function.\n",
    "\n",
    "# def main(verbose=False):\n",
    "#     baselearners = [DecisionTreeClassifier, \n",
    "#                     SVC, \n",
    "#                     MLPClassifier,\n",
    "#                     LogisticRegression]\n",
    "    \n",
    "#     for learner in baselearners:           \n",
    "#         if verbose:\n",
    "#             print(learner)\n",
    "#             evaluate(learner, True)\n",
    "#             print()\n",
    "#         else:\n",
    "#             perf = evaluate(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 1.0\n",
      "mAUC_train: 1.0\n",
      "\tTest metrics\n",
      "BCA_test: 0.8249257552483359\n",
      "mAUC_test: 0.868694316436252\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.917524219782151\n",
      "mAUC_train: 0.9940879940039782\n",
      "\tTest metrics\n",
      "BCA_test: 0.8913722478238607\n",
      "mAUC_test: 0.9723823924731182\n"
     ]
    }
   ],
   "source": [
    "evaluate(DecisionTreeClassifier, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8802071684432008\n",
      "mAUC_train: 0.9742760310804081\n",
      "\tTest metrics\n",
      "BCA_test: 0.8583384536610343\n",
      "mAUC_test: 0.9650310419866872\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8229333344551334\n",
      "mAUC_train: 0.9630247237742404\n",
      "\tTest metrics\n",
      "BCA_test: 0.8276241679467486\n",
      "mAUC_test: 0.9594310035842294\n"
     ]
    }
   ],
   "source": [
    "evaluate(SVC, True, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8872009613827309\n",
      "mAUC_train: 0.9741941233096751\n",
      "\tTest metrics\n",
      "BCA_test: 0.8875448028673835\n",
      "mAUC_test: 0.9695721326164874\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8052836460000696\n",
      "mAUC_train: 0.9566161506035402\n",
      "\tTest metrics\n",
      "BCA_test: 0.793200204813108\n",
      "mAUC_test: 0.9537624807987711\n"
     ]
    }
   ],
   "source": [
    "evaluate(MLPClassifier, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8097880755915684\n",
      "mAUC_train: 0.9601234307359686\n",
      "\tTest metrics\n",
      "BCA_test: 0.7994905273937531\n",
      "mAUC_test: 0.9592767537122375\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.7232919225481128\n",
      "mAUC_train: 0.9453789312376237\n",
      "\tTest metrics\n",
      "BCA_test: 0.7256426011264722\n",
      "mAUC_test: 0.9463194444444444\n"
     ]
    }
   ],
   "source": [
    "evaluate(LogisticRegression, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
