{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# import custom class\n",
    "from tadpole import Tadpole\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize class\n",
    "tp = Tadpole(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tadpole dataset\n",
      "pre-processing dataset\n",
      "{0: 'AD', 1: 'CN', 2: 'MCI'}\n"
     ]
    }
   ],
   "source": [
    "# load and pre-process tadpole dataset\n",
    "tp.load()\n",
    "print(tp.label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split data into Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting dataset to train and test datasets\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "tp.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import variables from class instance (notebook compatibility)\n",
    "label_dict = tp.label_dict\n",
    "X, y, X_train, X_test, y_train, y_test = tp.X, tp.y, tp.X_train, tp.X_test, tp.y_train, tp.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = sum(y_pred == y) / len(y)\n",
    "    return acc\n",
    "\n",
    "def metrics(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_prob = clf.predict_proba(X)\n",
    "    BCA = balanced_accuracy_score(y, y_pred)\n",
    "    mAUC = roc_auc_score(y, y_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "    return BCA, mAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_accuracy(clf):\n",
    "    train_acc = accuracy(clf, X_train, y_train)\n",
    "    test_acc = accuracy(clf, X_test, y_test)\n",
    "    print('Train accuracy:', train_acc)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    \n",
    "def report_metrics(clf, verbose):\n",
    "    BCA_train, mAUC_train = metrics(clf, X_train, y_train)\n",
    "    BCA_test, mAUC_test = metrics(clf, X_test, y_test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\tTrain metrics')    \n",
    "        print('BCA_train:', BCA_train)\n",
    "        print('mAUC_train:', mAUC_train)\n",
    "\n",
    "        print('\\tTest metrics')   \n",
    "        print('BCA_test:', BCA_test)\n",
    "        print('mAUC_test:', mAUC_test)\n",
    "    \n",
    "    return BCA_train, BCA_test, mAUC_train, mAUC_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings are not final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_clf(clf):\n",
    "    return BaggingClassifier(base_estimator = clf, \n",
    "                             n_estimators = 100, \n",
    "                             max_samples = 0.3, \n",
    "                             random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Classifier, verbose=False, **kwargs):\n",
    "    if verbose: print('+ Base learner')\n",
    "    clf = Classifier(**kwargs).fit(X_train, y_train)\n",
    "    clf_perf = report_metrics(clf, verbose)\n",
    "    \n",
    "    if verbose: print('\\n+ Ensemble')\n",
    "    bag_clf = bagging_clf(Classifier(**kwargs)).fit(X_train, y_train)\n",
    "    bag_clf_perf = report_metrics(bag_clf, verbose)\n",
    "    \n",
    "    # Values in dict are lists of the following format: \n",
    "    # BCA_train, BCA_test, mAUC_train, mAUC_test\n",
    "    if not verbose:\n",
    "        return {'clf': list(clf_perf), 'bag_clf': list(bag_clf_perf)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a main for every baselearner that runs them multiple times\n",
    "# because SVC requires extra arguments, which makes it difficult\n",
    "# to generalize into one function.\n",
    "\n",
    "# def main(verbose=False):\n",
    "#     baselearners = [DecisionTreeClassifier, \n",
    "#                     SVC, \n",
    "#                     MLPClassifier,\n",
    "#                     LogisticRegression]\n",
    "    \n",
    "#     for learner in baselearners:           \n",
    "#         if verbose:\n",
    "#             print(learner)\n",
    "#             evaluate(learner, True)\n",
    "#             print()\n",
    "#         else:\n",
    "#             perf = evaluate(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 1.0\n",
      "mAUC_train: 1.0\n",
      "\tTest metrics\n",
      "BCA_test: 0.8392703533026115\n",
      "mAUC_test: 0.8794527649769585\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.917524219782151\n",
      "mAUC_train: 0.9940879940039782\n",
      "\tTest metrics\n",
      "BCA_test: 0.8913722478238607\n",
      "mAUC_test: 0.9723823924731182\n"
     ]
    }
   ],
   "source": [
    "evaluate(DecisionTreeClassifier, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8802071684432008\n",
      "mAUC_train: 0.9744220473927845\n",
      "\tTest metrics\n",
      "BCA_test: 0.8583384536610343\n",
      "mAUC_test: 0.9652243343573988\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8237022676956377\n",
      "mAUC_train: 0.9630591443422594\n",
      "\tTest metrics\n",
      "BCA_test: 0.8315924219150026\n",
      "mAUC_test: 0.9595238095238096\n"
     ]
    }
   ],
   "source": [
    "evaluate(SVC, True, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8780358401126286\n",
      "mAUC_train: 0.9731710602670772\n",
      "\tTest metrics\n",
      "BCA_test: 0.873973374295955\n",
      "mAUC_test: 0.968514144905274\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8052836460000696\n",
      "mAUC_train: 0.9566161506035402\n",
      "\tTest metrics\n",
      "BCA_test: 0.793200204813108\n",
      "mAUC_test: 0.9537624807987711\n"
     ]
    }
   ],
   "source": [
    "evaluate(MLPClassifier, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Base learner\n",
      "\tTrain metrics\n",
      "BCA_train: 0.8097880755915684\n",
      "mAUC_train: 0.9601234307359686\n",
      "\tTest metrics\n",
      "BCA_test: 0.7994905273937531\n",
      "mAUC_test: 0.9592767537122375\n",
      "\n",
      "+ Ensemble\n",
      "\tTrain metrics\n",
      "BCA_train: 0.7232919225481128\n",
      "mAUC_train: 0.9453789312376237\n",
      "\tTest metrics\n",
      "BCA_test: 0.7256426011264722\n",
      "mAUC_test: 0.9463194444444444\n"
     ]
    }
   ],
   "source": [
    "evaluate(LogisticRegression, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
